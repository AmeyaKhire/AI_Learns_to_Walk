{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AIES Mini Project Topic: AI Agent Learns To Walk\n",
        "# Group Members:\n",
        "# Ameya Khire PB 05\n",
        "# Sahil Ranawade PB 16\n",
        "# Deven Chhajed PB 32\n",
        "                    "
      ],
      "metadata": {
        "id": "7taRTqdIplzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "ZLqPsmQrqNHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql6tO00eqRS8",
        "outputId": "86ce9e13-36d8-4c1b-97c0-036286f03abd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/953.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m952.3/953.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tn8ktfxqSQh",
        "outputId": "800366ae-42da-42e3-b054-8c17f80fab84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.1.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1.post0\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1.post0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373077 sha256=283990360a0ffa6ded92b5861f597ab960d94b86e5f0ab02a0bde4203fc90aa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the package lists for upgrades for packages that need upgrading,\n",
        "# as well as new packages that have just come to the repositories.\n",
        "!sudo apt-get update\n",
        "\n",
        "# Install necessary dependencies for creating virtual displays, handling video,\n",
        "# and graphical user interface toolkits for rendering environments.\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "\n",
        "# Install a specific version of the 'imageio' library (version 2.4.0)\n",
        "# for handling images and videos in Python.\n",
        "!pip install 'imageio==2.4.0'\n",
        "\n",
        "# Install the 'matplotlib' library for creating visualizations and plots in Python.\n",
        "!pip install matplotlib\n",
        "\n",
        "# Install 'pyvirtualdisplay' for managing and creating virtual displays\n",
        "# required for rendering environments in headless systems.\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "# Install 'tf-agents' with the 'reverb' extension for working with reinforcement learning agents.\n",
        "!pip install tf-agents[reverb]\n",
        "\n",
        "# Install 'pyglet', a cross-platform windowing and multimedia library used for\n",
        "# the construction of simple games and graphical applications in Python.\n",
        "!pip install pyglet\n",
        "\n",
        "# Install 'pybullet', a physics engine used for robotics, AI, and reinforcement learning.\n",
        "!pip install pybullet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBMhPYddqUYn",
        "outputId": "bae6e1a4-376a-430d-c7ce-1ea6456e0e2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r            \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.6 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [632 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,265 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,292 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,027 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,494 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
            "Fetched 9,186 kB in 2s (5,561 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev\n",
            "  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libice-dev libopengl-dev libsm-dev libxfont2 libxkbfile1\n",
            "  libxt-dev x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev libxfont2\n",
            "  libxkbfile1 libxt-dev x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 25 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 9,075 kB of archives.\n",
            "After this operation, 18.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
            "Fetched 9,075 kB in 1s (15.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 25.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 120882 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../19-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../20-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../21-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../22-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../23-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../24-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Collecting imageio==2.4.0\n",
            "  Downloading imageio-2.4.0.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (9.4.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-py3-none-any.whl size=3303893 sha256=97595de5f8a9bfa96c251f6fcca3d91369e8a3146566c4ff282b8cc706f5a7d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/d8/1c/eb9350a4bd3ae8e8814a2f7f9cc832fedad8ea5a926181d60d\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.0 which is incompatible.\n",
            "scikit-image 0.19.3 requires imageio>=2.4.1, but you have imageio 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.18.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents[reverb])\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Collecting pygame==2.1.3 (from tf-agents[reverb])\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.22.0)\n",
            "Collecting rlds (from tf-agents[reverb])\n",
            "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb~=0.13.0 (from tf-agents[reverb])\n",
            "  Downloading dm_reverb-0.13.0-cp310-cp310-manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-agents[reverb]) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.13.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.2.2)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697630 sha256=5b00969d729256e642b0540ade078e27da283ea1695d104a3b56e671e18c4978\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
            "Successfully built gym\n",
            "Installing collected packages: rlds, pygame, gym, tf-agents, dm-reverb\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed dm-reverb-0.13.0 gym-0.23.0 pygame-2.1.3 rlds-0.1.8 tf-agents-0.18.0\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.10-py3-none-any.whl (858 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.3/858.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.10\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "AgzIVEm6qY9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64  # Module providing functions for encoding and decoding binary data into text\n",
        "import imageio  # Library for reading and writing image data\n",
        "import IPython  # Interactive computing in Python\n",
        "import matplotlib.pyplot as plt  # Library for creating visualizations and plots\n",
        "import os  # Module providing functions to interact with the operating system\n",
        "import reverb  # Deep learning library for reinforcement learning\n",
        "\n",
        "import tempfile  # Module for working with temporary files and directories\n",
        "import PIL.Image  # Python Imaging Library for opening, manipulating, and saving many different image file formats\n",
        "import pyvirtualdisplay  # Library for managing and creating virtual displays\n",
        "import reverb  # Deep learning library for reinforcement learning\n",
        "\n",
        "import tensorflow as tf  # Open-source machine learning framework by Google\n",
        "\n",
        "from tf_agents.agents.ddpg import critic_network  # Importing specific component for DDPG agent\n",
        "from tf_agents.agents.sac import sac_agent  # Importing SAC (Soft Actor-Critic) agent\n",
        "from tf_agents.agents.sac import tanh_normal_projection_network  # Network to map hidden layers to a normal distribution\n",
        "from tf_agents.environments import suite_pybullet  # Provides access to PyBullet environments\n",
        "from tf_agents.metrics import py_metrics  # Metrics for TensorFlow Agents\n",
        "from tf_agents.networks import actor_distribution_network  # Actor Network for distributing actions\n",
        "from tf_agents.policies import greedy_policy  # Greedy policy for TensorFlow Agents\n",
        "from tf_agents.policies import py_tf_eager_policy  # Eager execution policy for Python\n",
        "from tf_agents.policies import random_py_policy  # Policy that selects random actions\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer  # Replay buffer for TensorFlow Agents\n",
        "from tf_agents.replay_buffers import reverb_utils  # Utility functions for Reverb replay buffers\n",
        "from tf_agents.train import actor  # Actor for training in TensorFlow Agents\n",
        "from tf_agents.train import learner  # Learner module for training\n",
        "from tf_agents.train import triggers  # Triggers for TensorFlow Agents training\n",
        "from tf_agents.train.utils import spec_utils  # Utility functions for TensorFlow Agents training\n",
        "from tf_agents.train.utils import strategy_utils  # Utility functions for TensorFlow Agents training\n",
        "from tf_agents.train.utils import train_utils  # Utility functions for TensorFlow Agents training"
      ],
      "metadata": {
        "id": "B1wTDklfqWbD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the path to the system's temporary directory and assign it to the variable 'tempdir'.\n",
        "tempdir = tempfile.gettempdir()"
      ],
      "metadata": {
        "id": "qZJ_5caqqcLh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and start a virtual display that is not visible (headless) with a specified size of 1400x900 pixels.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ],
      "metadata": {
        "id": "ZJqSivldqdk6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Demo"
      ],
      "metadata": {
        "id": "ROOd-iFmqfwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Gym library for reinforcement learning environments\n",
        "import gym\n",
        "\n",
        "# Import the suite of Gym environments from TensorFlow Agents\n",
        "import tf_agents.environments.suite_gym as suite_gym\n",
        "\n",
        "# Retrieve a list of all available Gym environments registered within Gym's environment registry\n",
        "available_gym_envs = list(gym.envs.registry.env_specs.keys())\n",
        "\n",
        "# Print a header indicating the display of available OpenAI Gym environments\n",
        "print(\"Available OpenAI Gym environments:\")\n",
        "\n",
        "# Iterate through the list of available Gym environments and print their names\n",
        "for env_name in available_gym_envs:\n",
        "    print(env_name)  # Display the name of each environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "940AJUZlqiOq",
        "outputId": "11f8ec1a-32a5-4182-cc02-4bdae4b46d05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available OpenAI Gym environments:\n",
            "CartPole-v0\n",
            "CartPole-v1\n",
            "MountainCar-v0\n",
            "MountainCarContinuous-v0\n",
            "Pendulum-v1\n",
            "Acrobot-v1\n",
            "LunarLander-v2\n",
            "LunarLanderContinuous-v2\n",
            "BipedalWalker-v3\n",
            "BipedalWalkerHardcore-v3\n",
            "CarRacing-v1\n",
            "Blackjack-v1\n",
            "FrozenLake-v1\n",
            "FrozenLake8x8-v1\n",
            "CliffWalking-v0\n",
            "Taxi-v3\n",
            "Reacher-v2\n",
            "Pusher-v2\n",
            "InvertedPendulum-v2\n",
            "InvertedDoublePendulum-v2\n",
            "HalfCheetah-v2\n",
            "HalfCheetah-v3\n",
            "Hopper-v2\n",
            "Hopper-v3\n",
            "Swimmer-v2\n",
            "Swimmer-v3\n",
            "Walker2d-v2\n",
            "Walker2d-v3\n",
            "Ant-v2\n",
            "Ant-v3\n",
            "Humanoid-v2\n",
            "Humanoid-v3\n",
            "HumanoidStandup-v2\n",
            "HumanoidDeepMimicBackflipBulletEnv-v1\n",
            "HumanoidDeepMimicWalkBulletEnv-v1\n",
            "CartPoleBulletEnv-v1\n",
            "CartPoleContinuousBulletEnv-v0\n",
            "MinitaurBulletEnv-v0\n",
            "MinitaurBulletDuckEnv-v0\n",
            "MinitaurExtendedEnv-v0\n",
            "MinitaurReactiveEnv-v0\n",
            "MinitaurBallGymEnv-v0\n",
            "MinitaurTrottingEnv-v0\n",
            "MinitaurStandGymEnv-v0\n",
            "MinitaurAlternatingLegsEnv-v0\n",
            "MinitaurFourLegStandEnv-v0\n",
            "RacecarBulletEnv-v0\n",
            "RacecarZedBulletEnv-v0\n",
            "KukaBulletEnv-v0\n",
            "KukaCamBulletEnv-v0\n",
            "KukaDiverseObjectGrasping-v0\n",
            "InvertedPendulumBulletEnv-v0\n",
            "InvertedDoublePendulumBulletEnv-v0\n",
            "InvertedPendulumSwingupBulletEnv-v0\n",
            "ReacherBulletEnv-v0\n",
            "PusherBulletEnv-v0\n",
            "ThrowerBulletEnv-v0\n",
            "Walker2DBulletEnv-v0\n",
            "HalfCheetahBulletEnv-v0\n",
            "AntBulletEnv-v0\n",
            "HopperBulletEnv-v0\n",
            "HumanoidBulletEnv-v0\n",
            "HumanoidFlagrunBulletEnv-v0\n",
            "HumanoidFlagrunHarderBulletEnv-v0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the name of the environment to be loaded\n",
        "env_name = 'BipedalWalker-v3'\n",
        "\n",
        "# Load the specified Gym environment using the suite_gym.load() function from TensorFlow Agents\n",
        "env = suite_gym.load(env_name)"
      ],
      "metadata": {
        "id": "YXaz4JPpsAsq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the environment and obtain the initial time step\n",
        "time_step = env.reset()\n",
        "\n",
        "# Display the information related to the time step\n",
        "print('Time step:')\n",
        "print(time_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ehCoscsBYu",
        "outputId": "fee6c170-a5ba-4e36-9a78-0a8412119be5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step:\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([ 2.7472735e-03, -2.6173826e-05,  2.0360595e-03, -1.5999826e-02,\n",
            "        9.1791026e-02, -2.6869071e-03,  8.6036575e-01,  3.3879888e-03,\n",
            "        1.0000000e+00,  3.2195445e-02, -2.6867248e-03,  8.5391831e-01,\n",
            "        1.9002074e-03,  1.0000000e+00,  4.4081411e-01,  4.4582021e-01,\n",
            "        4.6142289e-01,  4.8955029e-01,  5.3410292e-01,  6.0246116e-01,\n",
            "        7.0914906e-01,  8.8593203e-01,  1.0000000e+00,  1.0000000e+00],\n",
            "      dtype=float32),\n",
            " 'reward': array(0., dtype=float32),\n",
            " 'step_type': array(0, dtype=int32)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the numpy array to a PIL image\n",
        "PIL.Image.fromarray(env.render())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "HHYuuOlisSZE",
        "outputId": "190b605c-3a02-4909-e592-0d4ffffd9808"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=600x400>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Action"
      ],
      "metadata": {
        "id": "y_VAwgfksmti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the action specification of the environment\n",
        "print('Action Spec:')\n",
        "print(env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4gFmLLasaWU",
        "outputId": "76925044-aa1c-41b5-c4fe-f590849977a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Spec:\n",
            "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='action', minimum=-1.0, maximum=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation"
      ],
      "metadata": {
        "id": "lSsf392Tsvcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the observation specification of the environment\n",
        "print('Observation Spec:')\n",
        "print(env.time_step_spec().observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRrZongzstYU",
        "outputId": "7eaf94ff-0677-4d31-9657-15a60f236d4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Spec:\n",
            "BoundedArraySpec(shape=(24,), dtype=dtype('float32'), name='observation', minimum=-3.4028234663852886e+38, maximum=3.4028234663852886e+38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rewards"
      ],
      "metadata": {
        "id": "tu2YeHUNs2Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the reward specification of the environment\n",
        "print('Reward Spec:')\n",
        "print(env.time_step_spec().reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vfRY2gqs0Fq",
        "outputId": "82811ab9-f97d-40b3-a248-a783f5d2f657"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward Spec:\n",
            "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TtiE60fas9cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of iterations for training\n",
        "num_iterations = 100000\n",
        "\n",
        "# Steps for initial data collection\n",
        "initial_collect_steps = 10000\n",
        "\n",
        "# Number of steps to collect data in each iteration\n",
        "collect_steps_per_iteration = 1\n",
        "\n",
        "# Capacity of the replay buffer to store experiences\n",
        "replay_buffer_capacity = 10000\n",
        "\n",
        "# Batch size for training\n",
        "batch_size = 256\n",
        "\n",
        "# Learning rates for the critic, actor, and alpha (for entropy)\n",
        "critic_learning_rate = 3e-4\n",
        "actor_learning_rate = 3e-4\n",
        "alpha_learning_rate = 3e-4\n",
        "\n",
        "# Rate to update the target networks\n",
        "target_update_tau = 0.005\n",
        "target_update_period = 1\n",
        "\n",
        "# Discount factor for future rewards in the RL algorithm\n",
        "gamma = 0.99\n",
        "\n",
        "# Scaling factor for rewards\n",
        "reward_scale_factor = 1.0\n",
        "\n",
        "# Neural network layer sizes for the actor and critic networks\n",
        "actor_fc_layer_params = (256, 256)  # Hidden layers for actor\n",
        "critic_joint_fc_layer_params = (256, 256)  # Hidden layers for critic\n",
        "\n",
        "# Interval for logging during training\n",
        "log_interval = 5000\n",
        "\n",
        "# Number of episodes used for evaluation\n",
        "num_eval_episodes = 20\n",
        "\n",
        "# Interval for evaluating the trained policy\n",
        "eval_interval = 10000\n",
        "\n",
        "# Interval for saving the policy\n",
        "policy_save_interval = 5000"
      ],
      "metadata": {
        "id": "xuDy2kVjs6lM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the environment 'BipedalWalker-v3' for data collection using PyBullet suite\n",
        "collect_env = suite_pybullet.load(env_name)\n",
        "\n",
        "# Load the same environment 'BipedalWalker-v3' for evaluation using PyBullet suite\n",
        "eval_env = suite_pybullet.load(env_name)"
      ],
      "metadata": {
        "id": "NeH4BlpItGbE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the strategy for TensorFlow execution, specifying to not use TPU and to use GPU if available\n",
        "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=True)"
      ],
      "metadata": {
        "id": "RLHaocSytLvg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve specifications for observations, actions, and time steps from the environment\n",
        "observation_spec, action_spec, time_step_spec = spec_utils.get_tensor_specs(collect_env)"
      ],
      "metadata": {
        "id": "YLZ-hZ3ntPt2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a critic network within the specified TensorFlow strategy scope\n",
        "with strategy.scope():\n",
        "    # Create a CriticNetwork instance\n",
        "    critic_net = critic_network.CriticNetwork(\n",
        "        (observation_spec, action_spec),  # Specifications for observations and actions\n",
        "        observation_fc_layer_params=None,  # Parameters for observation fully connected layers (if any)\n",
        "        action_fc_layer_params=None,  # Parameters for action fully connected layers (if any)\n",
        "        joint_fc_layer_params=critic_joint_fc_layer_params,  # Parameters for joint fully connected layers\n",
        "        kernel_initializer=\"glorot_uniform\",  # Initialization method for kernel weights\n",
        "        last_kernel_initializer=\"glorot_uniform\"  # Initialization method for the last layer's kernel weights\n",
        "    )"
      ],
      "metadata": {
        "id": "jvZ3LE62tUP5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an actor network within the specified TensorFlow strategy scope\n",
        "with strategy.scope():\n",
        "    # Create an ActorDistributionNetwork instance\n",
        "    actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
        "        observation_spec,  # Specifications for observations\n",
        "        action_spec,  # Specifications for actions\n",
        "        fc_layer_params=actor_fc_layer_params,  # Fully connected layer parameters for the actor network\n",
        "        continuous_projection_net=(\n",
        "            tanh_normal_projection_network.TanhNormalProjectionNetwork\n",
        "        )  # Projection network for continuous action distribution\n",
        "    )"
      ],
      "metadata": {
        "id": "NrpSa9WatZRP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define operations within the specified TensorFlow strategy scope\n",
        "with strategy.scope():\n",
        "    # Create a training step function for the agent\n",
        "    train_step = train_utils.create_train_step()\n",
        "\n",
        "    # Instantiate a Soft Actor-Critic (SAC) agent\n",
        "    tf_agent = sac_agent.SacAgent(\n",
        "        time_step_spec,  # Specifications for time steps\n",
        "        action_spec,  # Specifications for actions\n",
        "        actor_network=actor_net,  # Actor network for the agent\n",
        "        critic_network=critic_net,  # Critic network for the agent\n",
        "        actor_optimizer=tf.keras.optimizers.Adam(learning_rate=actor_learning_rate),  # Optimizer for actor network\n",
        "        critic_optimizer=tf.keras.optimizers.Adam(learning_rate=alpha_learning_rate),  # Optimizer for critic network\n",
        "        alpha_optimizer=tf.keras.optimizers.Adam(learning_rate=alpha_learning_rate),  # Optimizer for alpha (entropy) adjustment\n",
        "        target_update_tau=target_update_tau,  # Parameter for target network update\n",
        "        target_update_period=target_update_period,  # Period for target network update\n",
        "        td_errors_loss_fn=tf.math.squared_difference,  # Loss function for TD errors\n",
        "        gamma=gamma,  # Discount factor\n",
        "        reward_scale_factor=reward_scale_factor,  # Scaling factor for rewards\n",
        "        train_step_counter=train_step  # Counter for train steps\n",
        "    )\n",
        "\n",
        "    # Initialize the SAC agent\n",
        "    tf_agent.initialize()"
      ],
      "metadata": {
        "id": "YgUXsirXtkHq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a table name and create a Reverb table instance\n",
        "table_name = \"uniform_table\"\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_capacity,  # Maximum size of the table (replay buffer capacity)\n",
        "    sampler=reverb.selectors.Uniform(),  # Selector for sampling from the table (Uniform sampling)\n",
        "    remover=reverb.selectors.Fifo(),  # Selector for removing items from the table (FIFO: First-In-First-Out)\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1)  # Rate limiter ensuring minimum table size for sampling\n",
        ")\n",
        "\n",
        "# Create a Reverb server with the defined table\n",
        "reverb_server = reverb.Server([table])"
      ],
      "metadata": {
        "id": "oC3mKzvgupoQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ReverbReplayBuffer instance\n",
        "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    tf_agent.collect_data_spec,  # Data specifications for the collected data by the agent\n",
        "    sequence_length=2,  # Length of sequences sampled from the replay buffer\n",
        "    table_name=table_name,  # Name of the Reverb table used for storing the data\n",
        "    local_server=reverb_server  # Local Reverb server managing the table\n",
        ")"
      ],
      "metadata": {
        "id": "Huc4DLN4uxP_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset from the Reverb replay buffer\n",
        "dataset = reverb_replay.as_dataset(\n",
        "    sample_batch_size=batch_size,  # Batch size for sampling from the replay buffer\n",
        "    num_steps=2  # Number of time steps in each element of the dataset\n",
        ").prefetch(50)  # Prefetch 50 elements for faster data retrieval\n",
        "\n",
        "# Define a function that returns the dataset\n",
        "experience_dataset_fn = lambda: dataset"
      ],
      "metadata": {
        "id": "qBx8Zy2uu4OC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the TensorFlow policy from the trained agent\n",
        "tf_eval_policy = tf_agent.policy\n",
        "\n",
        "# Create an evaluation policy using PyTFEagerPolicy\n",
        "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
        "    tf_eval_policy,  # TensorFlow policy obtained from the agent\n",
        "    use_tf_function=True  # Indicates the use of TensorFlow function for policy execution\n",
        ")"
      ],
      "metadata": {
        "id": "llrobBhzu9ZU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the TensorFlow policy for collecting experiences from the agent\n",
        "tf_collect_policy = tf_agent.collect_policy\n",
        "\n",
        "# Create a policy for collecting experiences using PyTFEagerPolicy\n",
        "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
        "    tf_collect_policy,  # TensorFlow collect policy obtained from the agent\n",
        "    use_tf_function=True  # Indicates the use of TensorFlow function for policy execution\n",
        ")"
      ],
      "metadata": {
        "id": "kEgS1maSvDRS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random policy for the environment using RandomPyPolicy\n",
        "random_policy = random_py_policy.RandomPyPolicy(\n",
        "    collect_env.time_step_spec(),  # Specifications for time steps\n",
        "    collect_env.action_spec()  # Specifications for actions\n",
        ")"
      ],
      "metadata": {
        "id": "yI9kZ7EivKA9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an observer to add trajectories to a Reverb table\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "    reverb_replay.py_client,  # PyReverb client associated with the replay buffer\n",
        "    table_name,  # Name of the Reverb table where trajectories are added\n",
        "    sequence_length=2,  # Length of trajectories to be added\n",
        "    stride_length=1  # Length of stride between added trajectories\n",
        ")"
      ],
      "metadata": {
        "id": "xy60MI80vTak"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an actor for initial data collection\n",
        "initial_collect_actor = actor.Actor(\n",
        "    collect_env,  # Environment used for data collection\n",
        "    random_policy,  # Random policy for the actor to take actions\n",
        "    train_step,  # Train step function for the actor\n",
        "    steps_per_run=initial_collect_steps,  # Number of steps to take per run (initial data collection)\n",
        "    observers=[rb_observer]  # List of observers, including the Reverb trajectory observer\n",
        ")\n",
        "\n",
        "# Run the initial data collection actor\n",
        "initial_collect_actor.run()"
      ],
      "metadata": {
        "id": "Lr7OVc-qvbLD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a metric to track environment steps\n",
        "env_step_metric = py_metrics.EnvironmentSteps()\n",
        "\n",
        "# Create an actor for ongoing data collection\n",
        "collect_actor = actor.Actor(\n",
        "    collect_env,  # The environment used for data collection\n",
        "    collect_policy,  # The policy employed by the actor to take actions\n",
        "    train_step,  # The function representing a single step of the training process\n",
        "    steps_per_run=1,  # Number of steps to take per run (ongoing data collection)\n",
        "    metrics=actor.collect_metrics(10),  # Metrics for the actor (collected every 10 steps)\n",
        "    summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),  # Directory for storing summaries\n",
        "    observers=[rb_observer, env_step_metric]  # List of observers for the actor\n",
        ")"
      ],
      "metadata": {
        "id": "_hI44PK_vgaT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an actor for evaluation episodes\n",
        "eval_actor = actor.Actor(\n",
        "    eval_env,  # The evaluation environment\n",
        "    eval_policy,  # The policy used for evaluation\n",
        "    train_step,  # The function representing a single step of the training process\n",
        "    episodes_per_run=num_eval_episodes,  # Number of episodes to run for evaluation\n",
        "    metrics=actor.eval_metrics(num_eval_episodes),  # Metrics for evaluation\n",
        "    summary_dir=os.path.join(tempdir, 'eval'),  # Directory for storing evaluation summaries\n",
        ")"
      ],
      "metadata": {
        "id": "tw3alP0LvpLO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to save the trained policy model\n",
        "saved_model_dir = os.path.join(tempdir, learner.POLICY_SAVED_MODEL_DIR)\n",
        "\n",
        "# List of triggers that control different actions during training\n",
        "learning_triggers = [\n",
        "    triggers.PolicySavedModelTrigger(\n",
        "        saved_model_dir,\n",
        "        tf_agent,\n",
        "        train_step,\n",
        "        interval=policy_save_interval  # Interval for saving the policy model\n",
        "    ),\n",
        "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),  # Log training step per second\n",
        "]\n",
        "\n",
        "# Create a Learner responsible for training the agent\n",
        "agent_learner = learner.Learner(\n",
        "    tempdir,  # Temporary directory for storing intermediate training artifacts\n",
        "    train_step,  # Function representing a single step of the training process\n",
        "    tf_agent,  # The agent being trained\n",
        "    experience_dataset_fn,  # Function returning the dataset for training\n",
        "    triggers=learning_triggers,  # Triggers that control training behavior\n",
        "    strategy=strategy  # The strategy for distributed training\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC1DYSC7vvax",
        "outputId": "0f2657e8-91b6-4401-8615-895dd338f04b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
            "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
            "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
            "WARNING:absl:`0/observation` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation`.\n",
            "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tf_agents.distributions.utils.SquashToSpecNormal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalDiag_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tf_agents.distributions.utils.SquashToSpecNormal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalDiag_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_metrics():\n",
        "    eval_actor.run()  # Execute the evaluation actor to perform evaluation episodes\n",
        "    results = {}  # Initialize an empty dictionary to store metric results\n",
        "    for metric in eval_actor.metrics:  # Iterate through the metrics associated with the evaluation actor\n",
        "        results[metric.name] = metric.result()  # Collect and store each metric's result in the dictionary\n",
        "    return results  # Return the collected metric results as a dictionary\n",
        "\n",
        "metrics = get_eval_metrics()  # Execute the function to gather evaluation metrics"
      ],
      "metadata": {
        "id": "tUcL2calv1hl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_eval_metrics(step, metrics):\n",
        "    # Joining metric names and their corresponding results into a formatted string\n",
        "    eval_results = (', ').join(\n",
        "        '{} = {:.6f}'.format(name, result) for name, result in metrics.items()\n",
        "    )\n",
        "    # Printing the formatted log message with step number and evaluation results\n",
        "    print('step = {0}: {1}'.format(step, eval_results))\n",
        "\n",
        "log_eval_metrics(0, metrics)  # Calling the function with step number 0 and the collected metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUK1S-rqxgrO",
        "outputId": "8a58e056-82f1-4a11-ffda-acdf13116f26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0: AverageReturn = -108.703812, AverageEpisodeLength = 356.100006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try-except block to potentially measure the execution time of this block, but it lacks the 'except' clause.\n",
        "\n",
        "# Set the initial training step counter to 0 for the agent\n",
        "tf_agent.train_step_counter.assign(0)\n",
        "\n",
        "# Obtain the initial evaluation metric 'AverageReturn' and store it in 'avg_return'\n",
        "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
        "\n",
        "# Initialize a list 'returns' with the initial average return value\n",
        "returns = [avg_return]\n",
        "\n",
        "# Loop for 'num_iterations' iterations\n",
        "for _ in range(num_iterations):\n",
        "    # Run the data collection actor to collect experiences\n",
        "    collect_actor.run()\n",
        "\n",
        "    # Perform a single iteration of agent learning using the agent learner\n",
        "    loss_info = agent_learner.run(iterations=1)\n",
        "\n",
        "    # Get the current training step from the agent learner\n",
        "    step = agent_learner.train_step_numpy\n",
        "\n",
        "    # Check if 'eval_interval' is set and if the current step is a multiple of 'eval_interval'\n",
        "    if eval_interval and step % eval_interval == 0:\n",
        "        # Obtain evaluation metrics using 'get_eval_metrics()'\n",
        "        metrics = get_eval_metrics()\n",
        "\n",
        "        # Log evaluation metrics at the current step using 'log_eval_metrics()'\n",
        "        log_eval_metrics(step, metrics)\n",
        "\n",
        "        # Append the 'AverageReturn' metric to the 'returns' list\n",
        "        returns.append(metrics[\"AverageReturn\"])\n",
        "\n",
        "    # Check if 'log_interval' is set and if the current step is a multiple of 'log_interval'\n",
        "    if log_interval and step % log_interval == 0:\n",
        "        # Print the current step and the loss information\n",
        "        print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n",
        "\n",
        "# Close the Reverb observer\n",
        "rb_observer.close()\n",
        "\n",
        "# Stop the Reverb server\n",
        "reverb_server.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcNe4BVwxn7f",
        "outputId": "b274f326-98e0-4d27-adcc-b9d2649cc8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 5000: loss = -25.937175750732422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the steps for x-axis based on eval_interval\n",
        "steps = range(0, num_iterations + 1, eval_interval)\n",
        "\n",
        "# Plot the average return against steps\n",
        "plt.plot(steps, returns)\n",
        "\n",
        "# Set labels for the axes\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Step')\n",
        "\n",
        "# Set limits for the y-axis (you need to specify appropriate values for y-axis limits)\n",
        "plt.ylim(0, max(returns) + 100)  # Example: Set the y-axis limit from 0 to the maximum return + 100"
      ],
      "metadata": {
        "id": "slqlZtaKyVJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import IPython.display\n",
        "\n",
        "def embed_mp4(filename):\n",
        "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "    video = open(filename, 'rb').read()\n",
        "    b64 = base64.b64encode(video).decode()\n",
        "    tag = '''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    '''.format(b64)\n",
        "\n",
        "    return IPython.display.HTML(tag)"
      ],
      "metadata": {
        "id": "cTjyD9EJyetm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign 'v1' as the value for the VERSION_NUMBER variable\n",
        "VERSION_NUMBER = 'v1'"
      ],
      "metadata": {
        "id": "SVV-ooRXy3ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of episodes to run for video generation\n",
        "num_episodes = 3\n",
        "\n",
        "# Define the video filename based on the VERSION_NUMBER variable\n",
        "video_filename = f'bipedal_walker_normal_{VERSION_NUMBER}.mp4'\n",
        "\n",
        "# Create the video using imageio to capture frames from the environment rendering\n",
        "with imageio.get_writer(video_filename, fps=60) as video:\n",
        "    # Loop through the specified number of episodes\n",
        "    for _ in range(num_episodes):\n",
        "        # Reset the environment for each episode and capture the initial rendering\n",
        "        time_step = eval_env.reset()\n",
        "        video.append_data(eval_env.render())\n",
        "\n",
        "        # Loop within an episode until it ends\n",
        "        while not time_step.is_last():\n",
        "            # Get the action from the evaluation actor's policy\n",
        "            action_step = eval_actor.policy.action(time_step)\n",
        "\n",
        "            # Take a step in the environment based on the selected action\n",
        "            time_step = eval_env.step(action_step.action)\n",
        "\n",
        "            # Capture the rendering after the step\n",
        "            video.append_data(eval_env.render())\n",
        "\n",
        "# Embed the generated video in the notebook using the 'embed_mp4()' function\n",
        "embed_mp4(video_filename)"
      ],
      "metadata": {
        "id": "6szNYQkry4ak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}